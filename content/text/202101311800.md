本ブログの入稿処理を Go で書き直しました。

ソースコードはこんな感じになってます。

[fijixxx/sublog-function](https://github.com/fijixxx/sublog-function)

## 経緯

爆速？！コンテナイメージからデプロイした Lambda のコールドスタートについて検証してみた #reinvent | Developers.IO

[https://dev.classmethod.jp/articles/measure-container-image-lambda-coldstart/](https://dev.classmethod.jp/articles/measure-container-image-lambda-coldstart/)

きっかけはこの記事です。

本ブログでは入稿を Lambda による FaaS で行っているのですが、この処理のコードを直接、インフラ管理用リポジトリ内に配置し AWS CDK のコードでインポートしていました。

```typescript
// sublog-infra/lib/sublog-infra-stack.ts

/**
 * 記事入稿用 Lambda セクション
 */
const sublog_upsert_Lambda = new lambda.Function(
  this,
  "sublog-upsert-meta-record",
  {
    functionName: "sublog-upsert-meta-record",
    runtime: lambda.Runtime.PYTHON_3_8,
    code: lambda.AssetCode.fromAsset("src/upsert"),
    // ↑ 同リポジトリ内の src ディレクトリから直接インポート
    handler: "upsert_meta.lambda_handler",
    role: executionLambdaRole,
    layers: [sublogLambdaLayer],
    timeout: Duration.seconds(30),
  }
);
```

![](https://res.cloudinary.com/dw8uhtxu4/image/upload/f_auto,q_auto/sublog/202101301.png)

インフラ管理のリポジトリにコンピューティングのコードが混じっている、ということで、このリポジトリが複数の役割を持つことになっていて、 `inra` のリポジトリ名から逸脱してしまっています。これはよくない、ということで、入稿処理のコードを別リポジトリに切り出し、ついでにコード自体のポータビリティを上げるために、 `Docker` コンテナにつつんであげます。

![](https://res.cloudinary.com/dw8uhtxu4/image/upload/f_auto,q_auto/sublog/202101303.png)

また、コードの中身自体も `Go` で書き直します。これにも理由はあって、

- Python, Node.js などで Lambda を書くと、依存パッケージのデプロイを考えないといけなくてめんどくさい（Go ならビルド成果物に全部入りで楽）
- バイナリ(実行環境のインストール不要)で動く Go の方が動作環境のサイズが小さく FaaS やコンテナのようにリソースを展開するところから始まる処理やデプロイ速度で有利
- そろそろ Go を書いてみたかった(流行ってる感じがする)

などが書き直しの理由です。

## 結果

結果から書くと、少なくとも自分の用途では Go on Docker で Lambda を無理してデプロイする必要はないかなーと感じました。

![](https://res.cloudinary.com/dw8uhtxu4/image/upload/f_auto,q_auto/sublog/202101302.png)

```typescript
// sublog-infra/lib/sublog-infra-stack.ts

/**
 * 記事入稿用 Lambda
 */
const sublog_upsert_Lambda = new lambda.Function(
  this,
  "sublog-upsert-meta-record",
  {
    functionName: "sublog-upsert-meta-record",
    runtime: lambda.Runtime.GO_1_X,
    code: new S3Code(srcBucket, "lambda/upsert/main.zip"),
    // ↑ ソースコード配置用バケットを新規作成して
    // そこにソースコードの zip を置く
    // AWS CDK 内でバケットを静的にインポートして、
    // ソースコード格納先のパスを Lambda 作成時に割当
    handler: "main",
    role: executionLambdaRole,
    timeout: Duration.seconds(30),
  }
);
```

最終的にはこんな感じになりました。

[sublog-infra/sublog-infra-stack.ts](https://github.com/fijixxx/sublog-infra/blob/843f9fb276b8e39848f74e9a6e390b5af42b318a/lib/sublog-infra-stack.ts)

理由としては以下です。

## Go on Docker on Lambda のコールドスタートが遅い

Docker イメージの大きさとは別に、起動のオーバーヘッドがあるような気がします。

```dockerfile
# Dockerfile

FROM golang:latest as builder
ENV GOPATH=
COPY . .
RUN GOOS=linux GOARCH=amd64 CGO_ENABLED=0 go build -o /dist/main upsert/cmd/lambda/main.go && mv entry.sh /dist/

FROM alpine:3.12.3
ADD https://github.com/aws/aws-lambda-runtime-interface-emulator/releases/latest/download/aws-lambda-rie /usr/bin/aws-lambda-rie
COPY --from=builder /dist/ /
RUN chmod 755 /usr/bin/aws-lambda-rie && chmod 755 /entry.sh
ENTRYPOINT [ "/entry.sh" ]
CMD [ "/main" ]
```

Go on Docker Lambda のイメージの作り方は公式のこのやり方を参考にしました。

[Deploy Go Lambda functions with container images - AWS Lambda](https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/go-image.html)

alpine は最新版(`3.12.3`)を使ったら ECR のスキャンに失敗したので、こちらを参考に `3.12.3` を使いました。

[[ECR] [request]: Support for Alpine 3.13 on Vulnerability Scans · Issue #1224 · aws/containers-roadmap](https://github.com/aws/containers-roadmap/issues/1224)

この Docker ファイルでビルドして ECR にアップロードします。

![](https://res.cloudinary.com/dw8uhtxu4/image/upload/f_auto,q_auto/sublog/2021-01-31-145858.png)

サイズは `17.91MB`。ちなみにローカルだと `42.3MB` です。

これに対して入稿処理をすると。。

```文言
REPORT RequestId: e45d283b-ee58-407b-8531-015d2a5cb573 Duration: 1306.27 ms Billed Duration: 3137 ms Memory Size: 128 MB Max Memory Used: 32 MB Init Duration: 1830.25 ms
```

`Init Duration: 1830.25 ms`

[上のクラメソさんの記事で 173MB のイメージの Init Duration が平均 471.7341ms](https://dev.classmethod.jp/articles/measure-container-image-lambda-coldstart/#toc-3)なことを考えると、妙に遅い気がします(何回か試しましたが、だいたい 1800 ms 前後な感じです。ただし、時折 200 ms で立ち上がったりする)。

これに対して、 zip を直接指定した場合はこんな感じになります。

```文言
REPORT RequestId: 9aaf7807-e0ca-47da-8577-1c30fe1ce16d Duration: 1279.56 ms Billed Duration: 1280 ms Memory Size: 128 MB Max Memory Used: 49 MB Init Duration: 114.72 ms
```

`Init Duration: 114.72 ms`

めっちゃ早いです。**ブログの入稿処理は十中八九コールドスタートになる**こと、実処理時間である Duration が `Duration: 1300 ms` 前後であることを考えると、この差は無視できないです(Docker Lambda を 1 回実行する時間で zip Lambda を 2 回実行できる)。

（ちなみに、 Python 時代はこんな感じでした。

```文言
REPORT RequestId: 4e6bdfc8-06f3-42d0-8430-052561db7f7a Duration: 4114.19 ms Billed Duration: 4115 ms Memory Size: 128 MB Max Memory Used: 94 MB Init Duration: 824.79 ms
```

**`Go` めっちゃ速！！**）

## なんでこんなに遅いのか

クラメソさんが re:invent の翻訳記事を上げているのですが、こんな記事があり Docker Lambda について解説がされています。

[[セッションレポート]Lambda のコンテナイメージ管理の裏側に詳しくなれるセッション SVS404 Deep dive into AWS Lambda security: Function isolation #reinvent | Developers.IO](https://dev.classmethod.jp/articles/reinvent2020-svs404/)

この記事の中で、以下のような記述があります。

```文言
IOの最適化
コンテナイメージ形式のLambdaでもハイパフォーマンスを実現するべくコンテナの中に何が入っているかを分析しました。 するとコンテナは共通のベースレイヤーから派生していることが多いと気付きました。例えばLambda用に提供しているベースレイヤーだったり、AWSが提供しているコンテナベースレイヤーだったり、OSSで広く使われているベースレイヤーだったり...です。つまり多くのコンテナイメージ間でデータの中身は共通部分が非常に多いのです。

コンテナイメージのもう1つの特性はIOがまばらであるということです。ファイルシステム上の全ファイルにアクセスしたり、ディスク上の全ブロックにアクセスするようなLambda Functionは非常に稀です。通常ランタイムの起動時にはいくつかのファイルを読み込み、ライブラリとデータセットをロードしますが、ディスク上の大部分にはアクセスしないのです。コンテナのワークロードを分析すると、ディスク上のブロックの数%しか読み書きしていないことは珍しくありませんでした。この特性はロード時間を最適化するための絶好のチャンスです。

コンテナイメージ形式のLambdaではコンテナイメージを小さなチャンクに分割し、それらのチャンクを必要に応じてオンデマンドでロードすることでLambda Functionの起動を高速化します。このアーキテクチャを採用すると、たとえコンテナイメージにファイルやライブラリを追加導入しても、それらのファイルにアクセスしない限りはLambda Function起動のオーバーヘッドは増えません。

...

FirecrackerのプロセスはMicroVMからのIOリクエストを処理しています。そしてFirecrackerのプロセスはローカルのSparse filesystemエージェントに対して読み書きが可能です。Sparse filesystemエージェントの内部にはいくつかの重要な概念があります。

まず1つ目はMicroVM専用のローカルキャッシュ(Dedicated local cache)です。このキャッシュにより高速なIOが可能になります。
もう1つはWrite overlayです。 LambdaのコードからFirecracker経由で流入する全ての書き込み要求はこのSparse filesystemエージェントで処理されます。後ほど説明しますがSparse fileSystemエージェントはKMS と統合されています。
Dedicated local cacheからの読み取りがキャッシュミスを引いた場合は、さらに物理マシン(Lambda Worker)上の共有ローカルキャッシュ(Shared local cache)を利用します。物理マシンは高速なローカルストレージを持ち、このローカルストレージは複数のSparse filesystemエージェントによって共有されています。
さらに3つ目のキャッシュとしてAZの共有ローカルキャッシュ(Shared AZ-local cache)があります。このローカルキャッシュはさらに大容量のキャッシュを持ちます。また、EC2ネットワークが高速なため、このローカルキャッシュからのロードも非常に高速に行われます。
```

なるほど、 ECR のコンテナイメージをチャンクで持ち、様々なレイヤーでキャッシュしている、と読み取れそうです。また、キャッシュレイヤーには共有のものも存在している、とのこと。

ということは、カスタムで Alpine を 1 からビルドするのではなく、**AWS 公式のイメージをベースに使用してビルドする**ことで OS 部分のキャッシュヒット率が上がり、コールドスタートも早くなる可能性があるのではないでしょうか？

逆に今は、 Alpine を 1 からビルドしているからキャッシュミスして遅いのではないかと。

ということで試してみました。

```dockerfile
# Dockerfile

FROM golang:latest as builder
ENV GOPATH=
COPY . .
RUN GOOS=linux GOARCH=amd64 CGO_ENABLED=0 go build -o /dist/main upsert/cmd/lambda/main.go

FROM public.ecr.aws/lambda/provided:al2
COPY bootstrap ${LAMBDA_RUNTIME_DIR}
RUN chmod 755 ${LAMBDA_RUNTIME_DIR}/bootstrap
COPY --from=builder /dist/ /
CMD [ "/main" ]
```

```shellscript
# bootstrap

#!/bin/sh
/main
```

公式のカスタムランタイム用の Alpine イメージを引っぱってきて、よしなに Go バイナリを配置して動かすように Dockerfile を変更します。

[Lambda のコンテナイメージサイズでスピンアップ速度はどれくらい変わるのか #awsreinvent - サーバーワークスエンジニアブログ](https://blog.serverworks.co.jp/reinvent2020-lambda-container-spinup)

[amazon/aws-lambda-provided - Docker Hub](https://hub.docker.com/r/amazon/aws-lambda-provided)

[AWS Lambda のカスタムランタイム - AWS Lambda](https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/runtimes-custom.html)

作り方などはこちらを参考にしました。

![](https://res.cloudinary.com/dw8uhtxu4/image/upload/f_auto,q_auto/sublog/2021-01-31-173442.png)

ECR 上でのサイズは `112.63MB` (ローカルでは `324MB`) と大きくなってしまいましたが、実行結果はどうでしょうか？

```文言
REPORT RequestId: 4e32229c-9947-4f62-838c-08b6a702ea4e Duration: 1525.96 ms Billed Duration: 1775 ms Memory Size: 128 MB Max Memory Used: 48 MB Init Duration: 248.12 ms
```

お！いい感じじゃないでしょうか。何回か試してみても `200.ms` 代で安定してる感じです(初回だけ 2400ms ぐらいかかった)

ということで、「なんでこんなに遅いのか」の問に対する答えとしては「Alpine を 1 からビルドの Docker コンテナを使用するとイメージを毎回ロードすることになってコールドスタートが遅く、対策として AWS 公式の Alpine イメージを使用すると、うまい具合に OS レイヤーのキャッシュを利用できてコールドスタートが速くなる」が言えるんじゃないでしょうか(あくまで仮説ですが)。

## 結果

以上を踏まえて、今回は `zip` からデプロイを選択しました(ズコーッ)。

いや、だって `AWS 公式イメージ` を使ったらそれはもうロックインじゃないですか。。今回、 `Docker` を使おうと思ったきっかけはポータビリティを考えて、だったので、こうなるともう `zip` の方がポータビリティあるかなと。

## Go について

思い出したように書きますが `Go` での開発体験は非常によかったです。

ちゃんと型とコンパイルによるチェックがあるのに言語のルール自体は覚えること少なく書き始められますし、動作自体も軽快です(入稿処理に関しては 4.1s → 1.2s まで縮みました)。あとはやっぱりビルド後のバイナリだけデプロイしたらいいところがライブラリ管理面で優しくて感動です。

それと、これは言語自体の問題ではないのかもしれませんが、 Python と比べて Go の方が VSCode の補完や GoDoc のような、開発用の補助リソースが充実している気がします。まあこれは自分がある程度知ってる Python についてはその辺に無頓着で、よく知らない Go についてはよく調べながら書き始めたからかもしれませんが。。

これからはフロント以外はどんどん Go 使っていきたいなー、っていうぐらい気に入りました。
